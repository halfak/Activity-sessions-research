In 2012, we had an idea for a measurement strategy that would bring insight and understanding to the nature of participation in an online community.  While studying the nature of participation in Wikipedia, the open, collaborative encyclopedia, we found ourselves increasingly curious about the amount of time that volunteer contributors invested into the encyclopedia's construction.  Past work had relied on counting the number of contributions made by a user\footnote{for example, ``Wikipedian is first to hit 1 million edits'' \url{http://www.dailydot.com/news/wikipedian-first-1-million-edits}} as a measure of investment, but we felt that the amount of time editors invested into editing might serve as a more accurate measure.

The measurement strategy we came up with was based on the clustering of Wikipedia editors' activities into ``edit sessions'' with the assumption that the duration of an edit session would represent a lower bound of the amount of time invested into Wikipedia contributions\cite{geiger2013using}.  Through our ethnographic work in Wikipedia we had found the notion of work sessions to be intuitive, yet there did not appear to be a consensus in the literature on how to identify work sessions from timestamped user activities.  This led us to look to the data itself for insight on what might be a reasonable approach to delineating users' editing activity into sessions. The regularities we found in inter-activity time amazed us with their intuitiveness and the simplicity of session demarcation implied. It is that work that led us to look for such regularities in other systems and to write this paper in order to share our results.

We are not the first to try our hands at identifying a reasonable way to measure user session behavior in human-computer interaction.  User sessions have been used extensively to generate metrics for understanding the performance of information resources~\cite{govseva2006empirical} -- especially in the domain of search~\cite{donato2010you,eickhoff2014lessons} and content personalisation~\cite{gomory1999analysis,spiliopoulou2003framework}. Despite this interest in understanding the nature and manifestation of user sessions, no clear consensus has emerged.  In fact, some work has gone as far as to argue that sessions don't actually exist as a useful divide for user activity~\cite{jones2008beyond} and that the strategy of choosing a global inactivity threshold is arbitrary~\cite{montgomery2001identifying}.

In this paper, we propose and demonstrate a strategy for identifying user sessions from log data and demonstrate how the results match both intuition and theory about goal-directed human activity.  We also show how this strategy yields consistent results across many different types of systems and user activities.  First, we will summarize previous work trying to make sense of user session behavior from log data.  Then we discuss theoretical arguments about how intuitive user behavior (e.g. tasks and sessions) ought to manifest in the data.  Third, we discuss a generalized version of the session threshold identification strategy we developed in~\cite{geiger2013using} and present strategies for identifying optimal thresholds in new data.  Then, we introduce 6 different systems from which we have extracted 10 different types of user actions for analysis and comparison. Finally, we conclude with discussions of the regularities and irregularities between datasets and what that might imply for both our understanding of the measurement of human behavior and the design of user-facing systems
