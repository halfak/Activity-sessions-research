In 2012, we had an idea for a measurement strategy that would bring insight and understanding to the nature of work in an online community.  While studying volunteer participation in Wikipedia, the open, collaborative encyclopedia, we found ourselves increasingly curious about the amount of time that volunteer contributors invested into the encyclopedia's construction.  Past work measuring Wikipedia editor engagement relied on counting the number of contributions made by a user\footnote{for example, ``Wikipedian is first to hit 1 million edits'' \url{http://www.dailydot.com/news/wikipedian-first-1-million-edits}}, but we felt that the amount of time editors spent editing might serve as a more appropriate measure.

The measurement strategy we came up with was based on the clustering of Wikipedia editors' activities into ``edit sessions'' with the assumption that the duration of an edit session would represent a lower bound of the amount of time invested into Wikipedia contributions~\cite{geiger2013using}.  Through our ethnographic work in Wikipedia we had found the notion of a work session to be intuitive, yet there did not appear to be a consensus in the literature on how to identify work sessions from timestamped user activities.  This led us to look to the data for insight about what might be a reasonable approach to delineating users' editing activity into sessions.  The regularities we found in inter-activity time amazed us with their intuitiveness and the simplicity of session demarcation they implied. It is that work that led us to look for such regularities in other systems and to write this paper to share our results.

We are not the first to try our hands at identifying a reasonable way to measure user session behavior in human-computer interaction.  User sessions have been used extensively to generate metrics for understanding the performance of information resources~\cite{govseva2006empirical} -- especially in the domain of search~\cite{donato2010you,eickhoff2014lessons} and content personalisation~\cite{gomory1999analysis,spiliopoulou2003framework}. Despite this interest in understanding the nature and manifestation of user sessions, no clear consensus about how to perform session identification has emerged.

Some have have even argued that human behavior is best understood as a series of goal-driven tasks as opposed to activity sessions and that the common strategy of choosing a global inactivity threshold is ineffective at identifying the boundaries of such tasks~\cite{jones2008beyond}.  We draw from Activity Theory~\cite{nardi1996context} to conceptualize tasks as sub-session activities and argue that both are are important for undertanding goal-oriented human behavior.

In this paper, we describe a strategy for identifying user sessions from log data and demonstrate how the results match both intuition and theory about goal-directed human activity.  We also show how this strategy yields consistent results across many different types of systems and user activities.  First, we summarize previous work which attempts to make sense of user session behavior from log data.  Then we discuss theoretical arguments about how goal-directed user behavior ought to manifest in the data.  Third, we discuss a generalized version of the inactivity threshold identification strategy we developed in previous work~\cite{geiger2013using} and present strategies for identifying optimal inactivity thresholds in new data.  Then, we introduce 6 different systems from which we have extracted 10 different types of user actions for analysis and comparison.  Finally, we conclude with discussions of the regularities and irregularities between datasets and what that might imply for both our understanding of the measurement of human behavior and the design of user-facing systems
