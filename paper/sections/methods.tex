This section is intended to both serve as a description of our methodology as well as to instruct readers on how to apply the same methods to their own datasets.  First, we will discuss how we recommend applying our methodology for identifying inter-activity type component clusters to a dataset.  Then we  describe the origin of our datasets and the cleanup we performed in order to remove artifacts.

\subsection{Fitting inter-activity times}
First, we must gather a dataset of user-initiated actions with timestamps of at least \emph{seconds} resolution.  We generate inter-activity times on a per-user basis, so a relatively robust user identifier is necessary.  While a persistent user identifier such as one associated with a user account is preferable, we have found that in the case of request logs, a fingerprint based on the request's IP and User-agent seems to be sufficient.

Once we have generated per-user inter-activity times, we plot a histogram based on the logarithmically scaled inter-activity time and look for evidence of a valley.  Given the observations we have seen (and report in section~\ref{sec:results_and_discussion}), we expect to see a valley around about 1 hour with peaks around 1 minute and 1 day.  It is at this time that anomalies in the data should be detected and removed.  For example, we found that the time between Wikimedia Mobile Views (described in the next section) had an absurd spike at exactly 18 minutes of inter-activity time caused by a few (likely automated) users and removed their activities from the dataset.

Next, we try to fit a two component gaussian mixture model using expectation maximization~\cite{benaglia2009mixtools} and visually inspect the results\footnote{Note that we tried several strategies for statistically confirming the most appropriate fit -- of which we found Davies--Bouldin index(DBI)~\cite{davies1979cluster} to be most reasonable -- but none were as good as a simple visual inspection, so we employ and recommend the same.}  When the simple bimodal components did not appear to fit the data appropriately, we explored the addition of components to the mixture model with careful skepticism and repeated visual inspection.

Finally, if we have found what appears to be an appropriate fit, we identify a theoretically optimal inter-activity threshold for identifying sessions by finding the point where inter-activity time is equally likely to be within the gaussians fit with sub-hour means (within-session) and gaussians fit with means beyond an hour (between-session).

\subsection{Datasets}
To test this approach to session identification, we used a variety of datasets covering multiple sites, user groups and types of action.

\leadin{Wikimedia sites.} One of the broadest groups of datasets comes from the Wikimedia websites (such as Wikipedia) and covers both page views (read actions) and edits. For the page views, we gather three datasets, each consisting of randomly-sampled page view events from the Wikimedia request logs. These covered app views (page views from the Wikimedia's official mobile app), mobile views (page views to the mobile site) and desktop views (page views to the desktop site). 100,000 IP addresses (or UUIDs, in the case of the app, since it has those built in) were selected, and all requests from those IPs/UUIDs for the month of October 2014 were retrieved. For desktop and mobile views, a UUID was produced by hashing the IP address, the User agent, and the accept\_language provided with each request. After filtering out known crawlers and automata using tobie's ua-parser\footnote{\url{https://github.com/tobie/ua-parser}}, we arrived at three page view datasets consisting of 2,376,891, 932,754 and 2,285,521 pageviews, respectively. These came from 100,000, 235,067 or 247,269 UUIDs. We also extracted inter-edit times from the English Wikipedia using the methodology we employed in~\cite{geiger2013using} -- randomly selecting 1 million edits from 157,342 registered users.

\leadin{AOL search} Contrasting with the Wikimedia datasets we used the (now infamous) AOL search logs\footnote{These logs are controversial due to their inclusion of search terms containing private information, and there has historically been an ethical debate about their use. We are confident, however, that our usage does not have ethical implications; we modified the dataset to strip search terms so that it consists solely of unique IDs and timestamps, as has been used in the past.\cite{mehrzadi2012onextracting}  See \url{https://en.wikipedia.org/wiki/AOL_search_data_leak} for more discussion.} (aol, search) consisting of 36,389,567 search actions from 657,427 unique IDs. These actions span from March through May of 2006.

\leadin{Cyclopath} We also gathered a dataset from Cyclopath, a computational geowiki leveraging cyclist knowledge~\cite{priedhorsky2008computational}.  The dataset consists of HTTP requests to the Cyclopath server that are automatically labelled by type.  We filtered these requests to include only those that represent a request for a cycle route between two points (cyclopath, route get). This came to 6,123 requests from 2,233 distinct registered users.

\leadin{Movielens} To explore different types of search and contributory behavor, we also extracted logs from the MovieLens movie recommender system, which has been in use since 1997. As of November 2014 there are 225,543 unique users who have provided more than 21 million movie ratings for more than 25,000 movies. From MovieLens, we extracted two datasets: (movielens, rating) consists of movie rating actions from between 1997 until 5 November 2014, and (movielens, search) consists of search actions from 19 December 2007 to 1 January 2014.

\leadin{StackOverflow}. This popular question/answer system relating to programming and software engineering regularly releases public data dumps. For our analysis, we extracted questions asked and answers posted between July 2008 and September 2013. The question dataset (stack overflow, question) consists of 6,397,301 questions from 1,191,748 distinct users, while the answer dataset (stack overflow, answer) consists of 11,463,991 answers from 790,713 distinct users.

\leadin{OpenStreetMap (OSM)} This open-source alternative mapping service also publishes regular database dumps. We downloaded a full history dump of OSM contributions as of 24 February 2014, restricting this to the North American region as defined by Geofabrik\footnote{\url{http://download.geofabrik.de/north-america.html}}, which consists of the United States, Canada and Greenland. OSM groups individual changes to the map into \textit{changesets}\footnote{\url{http://wiki.openstreetmap.org/wiki/API_v0.6#Changesets_2}} when an editor saves their work. We used the timestamp of the last revision in a changeset as the time that the user saved the changeset. The resulting dataset (osm, changeset) contains 13,388,923 million changesets from 46,595 distinct users.  We found that more than 75\% of changesets occured less than 5 seconds of inter-activity time.  We assumed that these represent a data import that set changeset timestamps to the same value and filtered them from the dataset.

\leadin{League of Legends} This widely-played online multiplayer game supports an extension that adds a rating system for users and logs games and play times for the wide set of users of the extension.  Notably, we used this dataset in previous work to study the effect of deviant behaviour on player retention~\cite{shores2014identification}. We took this dataset - consisting of roughly 2.5 million unique players participating in almost 166 million games - and extracted the time between when a user finished a game and started playing the next game (lol, game). Though not all games were captured (see~\cite{shores2014identification} for more details), missing data is believed to be most prevalent around newer players with less consistent play habits.

Taken together, these datasets represent seven different systems and include different interaction mechanisms (mobile apps, mobile devices, desktop devices and a video game interface), and different classes of interaction (web search \& route finding, contributions to collaboratively edited artifacts, page reads, and games played).
